{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yeild_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
    "\n",
    "\n",
    "\n",
    "yeild_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# Convert inputs and targets to tensors\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.0339, -0.0799, -0.0543],\n",
      "        [ 1.0528,  0.5236,  0.5564]], requires_grad=True)\n",
      "tensor([-0.6229,  1.7652], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Weights and biases\n",
    "w = torch.randn(2, 3, requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    return x @ w.t() + b # x[5,3][3,2] 5,2\n",
    "preds = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE loss\n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff * diff) / diff.numel()\n",
    "loss = mse(preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8034.6221, grad_fn=<DivBackward0>)\n",
      "tensor([[ 2.0339, -0.0799, -0.0543],\n",
      "        [ 1.0528,  0.5236,  0.5564]], requires_grad=True)\n",
      "None\n",
      "tensor([-0.6229,  1.7652], requires_grad=True)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "print(w)\n",
    "print(w.grad)\n",
    "print(b)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8034.6221, grad_fn=<DivBackward0>)\n",
      "tensor([[ 2.0339, -0.0799, -0.0543],\n",
      "        [ 1.0528,  0.5236,  0.5564]], requires_grad=True)\n",
      "tensor([[7684.7734, 5956.1152, 4098.7207],\n",
      "        [6471.2271, 5814.3936, 3789.3142]])\n",
      "tensor([-0.6229,  1.7652], requires_grad=True)\n",
      "tensor([85.0434, 73.7111])\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "print(w)\n",
    "print(w.grad) #dloss/dw\n",
    "print(b)\n",
    "print(b.grad) #dloss/dw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before:  tensor(8034.6221, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.8802, -0.1991, -0.1362],\n",
      "        [ 0.9234,  0.4073,  0.4806]], requires_grad=True)\n",
      "Loss After:  tensor(4717.4839, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(4717.4839, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.8267, -0.2338, -0.1619],\n",
      "        [ 0.8797,  0.3717,  0.4567]], requires_grad=True)\n",
      "Loss After:  tensor(3943.6362, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(3943.6362, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.7807, -0.2607, -0.1826],\n",
      "        [ 0.8429,  0.3433,  0.4372]], requires_grad=True)\n",
      "Loss After:  tensor(3412.6653, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(3412.6653, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.7410, -0.2810, -0.1992],\n",
      "        [ 0.8117,  0.3209,  0.4214]], requires_grad=True)\n",
      "Loss After:  tensor(3045.4841, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(3045.4841, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.7063, -0.2960, -0.2125],\n",
      "        [ 0.7850,  0.3032,  0.4086]], requires_grad=True)\n",
      "Loss After:  tensor(2788.7981, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(2788.7981, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.6758, -0.3066, -0.2231],\n",
      "        [ 0.7622,  0.2896,  0.3982]], requires_grad=True)\n",
      "Loss After:  tensor(2606.6880, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(2606.6880, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.6487, -0.3137, -0.2315],\n",
      "        [ 0.7424,  0.2792,  0.3899]], requires_grad=True)\n",
      "Loss After:  tensor(2474.9497, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(2474.9497, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.6245, -0.3178, -0.2381],\n",
      "        [ 0.7251,  0.2715,  0.3833]], requires_grad=True)\n",
      "Loss After:  tensor(2377.2690, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(2377.2690, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.6027, -0.3196, -0.2431],\n",
      "        [ 0.7100,  0.2660,  0.3780]], requires_grad=True)\n",
      "Loss After:  tensor(2302.6521, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(2302.6521, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.5827, -0.3194, -0.2469],\n",
      "        [ 0.6966,  0.2623,  0.3738]], requires_grad=True)\n",
      "Loss After:  tensor(2243.6885, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(2243.6885, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.5644, -0.3177, -0.2497],\n",
      "        [ 0.6846,  0.2600,  0.3706]], requires_grad=True)\n",
      "Loss After:  tensor(2195.3813, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(2195.3813, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.5475, -0.3146, -0.2517],\n",
      "        [ 0.6738,  0.2590,  0.3681]], requires_grad=True)\n",
      "Loss After:  tensor(2154.3647, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(2154.3647, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.5316, -0.3105, -0.2530],\n",
      "        [ 0.6640,  0.2589,  0.3662]], requires_grad=True)\n",
      "Loss After:  tensor(2118.3667, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(2118.3667, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.5167, -0.3055, -0.2537],\n",
      "        [ 0.6550,  0.2596,  0.3649]], requires_grad=True)\n",
      "Loss After:  tensor(2085.8564, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(2085.8564, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.5025, -0.2998, -0.2540],\n",
      "        [ 0.6467,  0.2609,  0.3639]], requires_grad=True)\n",
      "Loss After:  tensor(2055.8005, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(2055.8005, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.4889, -0.2936, -0.2539],\n",
      "        [ 0.6389,  0.2628,  0.3633]], requires_grad=True)\n",
      "Loss After:  tensor(2027.5006, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(2027.5006, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.4759, -0.2870, -0.2535],\n",
      "        [ 0.6315,  0.2652,  0.3630]], requires_grad=True)\n",
      "Loss After:  tensor(2000.4857, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(2000.4857, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.4634, -0.2800, -0.2529],\n",
      "        [ 0.6246,  0.2678,  0.3629]], requires_grad=True)\n",
      "Loss After:  tensor(1974.4369, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1974.4369, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.4512, -0.2727, -0.2520],\n",
      "        [ 0.6179,  0.2708,  0.3630]], requires_grad=True)\n",
      "Loss After:  tensor(1949.1375, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1949.1375, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.4394, -0.2651, -0.2510],\n",
      "        [ 0.6116,  0.2739,  0.3632]], requires_grad=True)\n",
      "Loss After:  tensor(1924.4407, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1924.4407, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.4278, -0.2574, -0.2499],\n",
      "        [ 0.6054,  0.2773,  0.3636]], requires_grad=True)\n",
      "Loss After:  tensor(1900.2463, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1900.2463, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.4165, -0.2496, -0.2486],\n",
      "        [ 0.5995,  0.2808,  0.3641]], requires_grad=True)\n",
      "Loss After:  tensor(1876.4856, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1876.4856, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.4054, -0.2417, -0.2473],\n",
      "        [ 0.5937,  0.2844,  0.3646]], requires_grad=True)\n",
      "Loss After:  tensor(1853.1107, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1853.1107, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.3945, -0.2337, -0.2459],\n",
      "        [ 0.5880,  0.2881,  0.3652]], requires_grad=True)\n",
      "Loss After:  tensor(1830.0892, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1830.0892, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.3837, -0.2257, -0.2444],\n",
      "        [ 0.5825,  0.2918,  0.3659]], requires_grad=True)\n",
      "Loss After:  tensor(1807.3961, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1807.3961, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.3731, -0.2176, -0.2429],\n",
      "        [ 0.5771,  0.2956,  0.3666]], requires_grad=True)\n",
      "Loss After:  tensor(1785.0164, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1785.0164, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.3626, -0.2095, -0.2413],\n",
      "        [ 0.5718,  0.2995,  0.3674]], requires_grad=True)\n",
      "Loss After:  tensor(1762.9355, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1762.9355, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.3522, -0.2014, -0.2398],\n",
      "        [ 0.5665,  0.3034,  0.3682]], requires_grad=True)\n",
      "Loss After:  tensor(1741.1451, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1741.1451, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.3420, -0.1933, -0.2382],\n",
      "        [ 0.5613,  0.3072,  0.3690]], requires_grad=True)\n",
      "Loss After:  tensor(1719.6367, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1719.6367, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.3318, -0.1853, -0.2365],\n",
      "        [ 0.5562,  0.3111,  0.3698]], requires_grad=True)\n",
      "Loss After:  tensor(1698.4045, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1698.4045, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.3217, -0.1772, -0.2349],\n",
      "        [ 0.5512,  0.3150,  0.3706]], requires_grad=True)\n",
      "Loss After:  tensor(1677.4434, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1677.4434, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.3118, -0.1692, -0.2333],\n",
      "        [ 0.5462,  0.3189,  0.3715]], requires_grad=True)\n",
      "Loss After:  tensor(1656.7484, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1656.7484, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.3019, -0.1612, -0.2316],\n",
      "        [ 0.5412,  0.3228,  0.3723]], requires_grad=True)\n",
      "Loss After:  tensor(1636.3157, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1636.3157, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.2920, -0.1533, -0.2300],\n",
      "        [ 0.5363,  0.3267,  0.3732]], requires_grad=True)\n",
      "Loss After:  tensor(1616.1410, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1616.1410, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.2823, -0.1454, -0.2283],\n",
      "        [ 0.5314,  0.3305,  0.3740]], requires_grad=True)\n",
      "Loss After:  tensor(1596.2211, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1596.2211, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.2726, -0.1375, -0.2267],\n",
      "        [ 0.5266,  0.3344,  0.3749]], requires_grad=True)\n",
      "Loss After:  tensor(1576.5521, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1576.5521, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.2630, -0.1297, -0.2250],\n",
      "        [ 0.5218,  0.3382,  0.3758]], requires_grad=True)\n",
      "Loss After:  tensor(1557.1313, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1557.1313, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.2534, -0.1219, -0.2234],\n",
      "        [ 0.5170,  0.3420,  0.3767]], requires_grad=True)\n",
      "Loss After:  tensor(1537.9550, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1537.9550, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.2440, -0.1141, -0.2217],\n",
      "        [ 0.5123,  0.3458,  0.3775]], requires_grad=True)\n",
      "Loss After:  tensor(1519.0201, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1519.0201, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.2345, -0.1064, -0.2201],\n",
      "        [ 0.5076,  0.3496,  0.3784]], requires_grad=True)\n",
      "Loss After:  tensor(1500.3230, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1500.3230, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.2252, -0.0988, -0.2184],\n",
      "        [ 0.5030,  0.3534,  0.3793]], requires_grad=True)\n",
      "Loss After:  tensor(1481.8616, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1481.8616, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.2159, -0.0912, -0.2168],\n",
      "        [ 0.4984,  0.3571,  0.3801]], requires_grad=True)\n",
      "Loss After:  tensor(1463.6327, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1463.6327, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.2067, -0.0836, -0.2152],\n",
      "        [ 0.4938,  0.3608,  0.3810]], requires_grad=True)\n",
      "Loss After:  tensor(1445.6331, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1445.6331, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.1975, -0.0761, -0.2136],\n",
      "        [ 0.4892,  0.3645,  0.3819]], requires_grad=True)\n",
      "Loss After:  tensor(1427.8596, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1427.8596, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.1884, -0.0687, -0.2119],\n",
      "        [ 0.4847,  0.3682,  0.3827]], requires_grad=True)\n",
      "Loss After:  tensor(1410.3097, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1410.3097, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.1793, -0.0612, -0.2103],\n",
      "        [ 0.4802,  0.3718,  0.3836]], requires_grad=True)\n",
      "Loss After:  tensor(1392.9807, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1392.9807, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.1703, -0.0539, -0.2087],\n",
      "        [ 0.4757,  0.3754,  0.3845]], requires_grad=True)\n",
      "Loss After:  tensor(1375.8694, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1375.8694, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.1614, -0.0466, -0.2071],\n",
      "        [ 0.4713,  0.3790,  0.3853]], requires_grad=True)\n",
      "Loss After:  tensor(1358.9734, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1358.9734, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.1525, -0.0393, -0.2055],\n",
      "        [ 0.4669,  0.3826,  0.3862]], requires_grad=True)\n",
      "Loss After:  tensor(1342.2898, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1342.2898, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.1437, -0.0320, -0.2039],\n",
      "        [ 0.4625,  0.3861,  0.3870]], requires_grad=True)\n",
      "Loss After:  tensor(1325.8163, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1325.8163, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.1349, -0.0249, -0.2023],\n",
      "        [ 0.4581,  0.3897,  0.3879]], requires_grad=True)\n",
      "Loss After:  tensor(1309.5499, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1309.5499, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.1262, -0.0177, -0.2008],\n",
      "        [ 0.4538,  0.3932,  0.3887]], requires_grad=True)\n",
      "Loss After:  tensor(1293.4879, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1293.4879, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.1175, -0.0106, -0.1992],\n",
      "        [ 0.4495,  0.3967,  0.3895]], requires_grad=True)\n",
      "Loss After:  tensor(1277.6278, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1277.6278, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.1089, -0.0036, -0.1976],\n",
      "        [ 0.4452,  0.4001,  0.3904]], requires_grad=True)\n",
      "Loss After:  tensor(1261.9672, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1261.9672, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.1004,  0.0034, -0.1961],\n",
      "        [ 0.4410,  0.4036,  0.3912]], requires_grad=True)\n",
      "Loss After:  tensor(1246.5035, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1246.5035, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.0919,  0.0103, -0.1945],\n",
      "        [ 0.4367,  0.4070,  0.3921]], requires_grad=True)\n",
      "Loss After:  tensor(1231.2341, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1231.2341, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.0834,  0.0173, -0.1930],\n",
      "        [ 0.4325,  0.4104,  0.3929]], requires_grad=True)\n",
      "Loss After:  tensor(1216.1569, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1216.1569, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.0750,  0.0241, -0.1914],\n",
      "        [ 0.4284,  0.4137,  0.3937]], requires_grad=True)\n",
      "Loss After:  tensor(1201.2689, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before:  tensor(1201.2689, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.0667,  0.0309, -0.1899],\n",
      "        [ 0.4242,  0.4171,  0.3945]], requires_grad=True)\n",
      "Loss After:  tensor(1186.5681, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1186.5681, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.0584,  0.0377, -0.1883],\n",
      "        [ 0.4201,  0.4204,  0.3954]], requires_grad=True)\n",
      "Loss After:  tensor(1172.0524, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1172.0524, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.0502,  0.0444, -0.1868],\n",
      "        [ 0.4160,  0.4237,  0.3962]], requires_grad=True)\n",
      "Loss After:  tensor(1157.7188, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1157.7188, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.0420,  0.0511, -0.1853],\n",
      "        [ 0.4119,  0.4270,  0.3970]], requires_grad=True)\n",
      "Loss After:  tensor(1143.5653, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1143.5653, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.0338,  0.0577, -0.1838],\n",
      "        [ 0.4079,  0.4303,  0.3978]], requires_grad=True)\n",
      "Loss After:  tensor(1129.5897, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1129.5897, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.0258,  0.0643, -0.1823],\n",
      "        [ 0.4039,  0.4335,  0.3986]], requires_grad=True)\n",
      "Loss After:  tensor(1115.7902, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1115.7902, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.0177,  0.0709, -0.1808],\n",
      "        [ 0.3999,  0.4367,  0.3994]], requires_grad=True)\n",
      "Loss After:  tensor(1102.1636, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1102.1636, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.0097,  0.0774, -0.1793],\n",
      "        [ 0.3959,  0.4399,  0.4002]], requires_grad=True)\n",
      "Loss After:  tensor(1088.7081, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1088.7081, grad_fn=<DivBackward0>)\n",
      "tensor([[ 1.0018,  0.0839, -0.1778],\n",
      "        [ 0.3920,  0.4431,  0.4010]], requires_grad=True)\n",
      "Loss After:  tensor(1075.4220, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1075.4220, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.9939,  0.0903, -0.1763],\n",
      "        [ 0.3881,  0.4462,  0.4018]], requires_grad=True)\n",
      "Loss After:  tensor(1062.3025, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1062.3025, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.9861,  0.0967, -0.1748],\n",
      "        [ 0.3842,  0.4494,  0.4026]], requires_grad=True)\n",
      "Loss After:  tensor(1049.3481, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1049.3481, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.9783,  0.1030, -0.1733],\n",
      "        [ 0.3803,  0.4525,  0.4034]], requires_grad=True)\n",
      "Loss After:  tensor(1036.5564, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1036.5564, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.9706,  0.1093, -0.1719],\n",
      "        [ 0.3764,  0.4556,  0.4042]], requires_grad=True)\n",
      "Loss After:  tensor(1023.9253, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1023.9253, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.9629,  0.1156, -0.1704],\n",
      "        [ 0.3726,  0.4587,  0.4050]], requires_grad=True)\n",
      "Loss After:  tensor(1011.4531, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(1011.4531, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.9552,  0.1218, -0.1690],\n",
      "        [ 0.3688,  0.4617,  0.4058]], requires_grad=True)\n",
      "Loss After:  tensor(999.1371, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(999.1371, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.9476,  0.1280, -0.1675],\n",
      "        [ 0.3650,  0.4647,  0.4066]], requires_grad=True)\n",
      "Loss After:  tensor(986.9761, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(986.9761, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.9401,  0.1341, -0.1661],\n",
      "        [ 0.3613,  0.4678,  0.4073]], requires_grad=True)\n",
      "Loss After:  tensor(974.9678, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(974.9678, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.9326,  0.1402, -0.1646],\n",
      "        [ 0.3576,  0.4707,  0.4081]], requires_grad=True)\n",
      "Loss After:  tensor(963.1105, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(963.1105, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.9251,  0.1462, -0.1632],\n",
      "        [ 0.3539,  0.4737,  0.4089]], requires_grad=True)\n",
      "Loss After:  tensor(951.4017, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(951.4017, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.9177,  0.1523, -0.1618],\n",
      "        [ 0.3502,  0.4767,  0.4097]], requires_grad=True)\n",
      "Loss After:  tensor(939.8401, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(939.8401, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.9104,  0.1582, -0.1603],\n",
      "        [ 0.3465,  0.4796,  0.4104]], requires_grad=True)\n",
      "Loss After:  tensor(928.4238, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(928.4238, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.9030,  0.1642, -0.1589],\n",
      "        [ 0.3429,  0.4825,  0.4112]], requires_grad=True)\n",
      "Loss After:  tensor(917.1506, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(917.1506, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.8958,  0.1701, -0.1575],\n",
      "        [ 0.3393,  0.4854,  0.4120]], requires_grad=True)\n",
      "Loss After:  tensor(906.0189, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(906.0189, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.8885,  0.1759, -0.1561],\n",
      "        [ 0.3357,  0.4883,  0.4127]], requires_grad=True)\n",
      "Loss After:  tensor(895.0272, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(895.0272, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.8814,  0.1817, -0.1547],\n",
      "        [ 0.3321,  0.4911,  0.4135]], requires_grad=True)\n",
      "Loss After:  tensor(884.1732, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(884.1732, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.8742,  0.1875, -0.1533],\n",
      "        [ 0.3286,  0.4940,  0.4142]], requires_grad=True)\n",
      "Loss After:  tensor(873.4556, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(873.4556, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.8671,  0.1933, -0.1519],\n",
      "        [ 0.3250,  0.4968,  0.4150]], requires_grad=True)\n",
      "Loss After:  tensor(862.8726, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(862.8726, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.8601,  0.1990, -0.1505],\n",
      "        [ 0.3215,  0.4996,  0.4157]], requires_grad=True)\n",
      "Loss After:  tensor(852.4224, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(852.4224, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.8531,  0.2046, -0.1491],\n",
      "        [ 0.3180,  0.5024,  0.4165]], requires_grad=True)\n",
      "Loss After:  tensor(842.1030, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(842.1030, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.8461,  0.2103, -0.1477],\n",
      "        [ 0.3146,  0.5051,  0.4172]], requires_grad=True)\n",
      "Loss After:  tensor(831.9133, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(831.9133, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.8392,  0.2159, -0.1464],\n",
      "        [ 0.3111,  0.5079,  0.4180]], requires_grad=True)\n",
      "Loss After:  tensor(821.8514, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(821.8514, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.8323,  0.2214, -0.1450],\n",
      "        [ 0.3077,  0.5106,  0.4187]], requires_grad=True)\n",
      "Loss After:  tensor(811.9160, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(811.9160, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.8255,  0.2269, -0.1436],\n",
      "        [ 0.3043,  0.5133,  0.4194]], requires_grad=True)\n",
      "Loss After:  tensor(802.1050, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(802.1050, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.8187,  0.2324, -0.1423],\n",
      "        [ 0.3010,  0.5160,  0.4202]], requires_grad=True)\n",
      "Loss After:  tensor(792.4172, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(792.4172, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.8119,  0.2379, -0.1409],\n",
      "        [ 0.2976,  0.5187,  0.4209]], requires_grad=True)\n",
      "Loss After:  tensor(782.8507, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(782.8507, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.8052,  0.2433, -0.1396],\n",
      "        [ 0.2943,  0.5213,  0.4216]], requires_grad=True)\n",
      "Loss After:  tensor(773.4044, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(773.4044, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.7986,  0.2487, -0.1382],\n",
      "        [ 0.2910,  0.5240,  0.4224]], requires_grad=True)\n",
      "Loss After:  tensor(764.0765, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(764.0765, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.7920,  0.2540, -0.1369],\n",
      "        [ 0.2877,  0.5266,  0.4231]], requires_grad=True)\n",
      "Loss After:  tensor(754.8657, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(754.8657, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.7854,  0.2593, -0.1356],\n",
      "        [ 0.2844,  0.5292,  0.4238]], requires_grad=True)\n",
      "Loss After:  tensor(745.7703, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(745.7703, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.7788,  0.2646, -0.1342],\n",
      "        [ 0.2811,  0.5318,  0.4245]], requires_grad=True)\n",
      "Loss After:  tensor(736.7890, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(736.7890, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.7723,  0.2698, -0.1329],\n",
      "        [ 0.2779,  0.5343,  0.4252]], requires_grad=True)\n",
      "Loss After:  tensor(727.9204, grad_fn=<DivBackward0>)\n",
      "Loss before:  tensor(727.9204, grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.7659,  0.2750, -0.1316],\n",
      "        [ 0.2747,  0.5369,  0.4260]], requires_grad=True)\n",
      "Loss After:  tensor(719.1628, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Update w = -\n",
    "# compute loss\n",
    "for i in range(100):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds,targets)\n",
    "    print(\"Loss before: \", loss)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -=  1e-5*w.grad\n",
    "        b -=  1e-5*b.grad\n",
    "        print(w)\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "    # compute loss\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds,targets)\n",
    "    print(\"Loss After: \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
